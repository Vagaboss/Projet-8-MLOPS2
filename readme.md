Lien github du projet : https://github.com/Vagaboss/Projet-8-MLOPS2

Projet effectuÃ© en 4 Ã©tapes.

# IMPORTANT
Fichiers datasets volumineux Ã  telecharger ici : 

https://drive.google.com/file/d/1wyJAoYRtNfZOetLwhRset6u2dNBBnaXA/view?usp=drive_link

Ensuite deplacer les 2 datasets vers le sous dossier datasets/


#  Etape 1 

ğŸ—‚ï¸ Structure du projet

Projet 8 MLOPS2/

â”œâ”€â”€ .git/                           
â”œâ”€â”€ .github/                        
â”œâ”€â”€ api/                          
â”œâ”€â”€ datasets/                     
â”œâ”€â”€ htmlcov/                       
â”œâ”€â”€ logs/                         
â”œâ”€â”€ models/                        
â”œâ”€â”€ notebook/                       
â”œâ”€â”€ tests/                       
â”œâ”€â”€ .gitattributes               
â”œâ”€â”€ .gitignore                      
â”œâ”€â”€ analyse_logs.py                 
â”œâ”€â”€ dashboard.py                    
â”œâ”€â”€ Dockerfile                      
â”œâ”€â”€ inference.py                  
â”œâ”€â”€ profiling.py                    
â”œâ”€â”€ profiling_output.prof           
â”œâ”€â”€ profiling_output3.prof          
â”œâ”€â”€ readme.md                       
â”œâ”€â”€ requirements.txt                
â””â”€â”€ train.py                       




#  Ã‰tape 2 â€“ DÃ©ploiement du modÃ¨le via une API Gradio + Docker + CI/CD


ğŸ¯ Objectif

Cette Ã©tape vise Ã  exposer le modÃ¨le de machine learning entraÃ®nÃ© Ã  l'Ã©tape 1 via une API accessible. 

âš™ï¸ Fonctionnement gÃ©nÃ©ral

1. Interface utilisateur (API Gradio)

Le fichier app_gradio.py contient la fonction principale predict_credit_score() qui :

ReÃ§oit des entrÃ©es utilisateur (11 features sÃ©lectionnÃ©es)

Retourne le rÃ©sultat dans une interface simple via Gradio

### lancement : python -m api.app_gradio

âœ… Lâ€™interface Gradio sâ€™ouvre dans un navigateur Ã  lâ€™adresse : http://localhost:7860

2. Conteneurisation avec Docker

Le Dockerfile permet de :

CrÃ©er une image contenant Python, les dÃ©pendances (requirements.txt) et les scripts


3. Automatisation via CI/CD

Le dossier .github/workflows/ contient le fichier YAML de configuration pour GitHub Actions. Ce pipeline CI/CD :

- Se dÃ©clenche automatiquement Ã  chaque push sur la branche principale

- Installe les dÃ©pendances

- ExÃ©cute les tests 

- Build lâ€™image Docker et dÃ©ployer sur Hugging Face Spaces 


ğŸ§ª Logs & Monitoring

La fonction log_prediction() dÃ©finit dans le fichier api/logger.py enregistre chaque appel Ã  lâ€™API dans le fichier predictions_log.jsonl avec :

- EntrÃ©es utilisateur

- Score et prÃ©diction

- Temps dâ€™exÃ©cution

- Utilisation CPU et RAM

Ces logs peuvent ensuite Ãªtre analysÃ©s via le fichier analyse_logs.py ou visualisÃ©s dans un dashboard.py.

âœ… Tests rÃ©alisÃ©s

Pour garantir le bon fonctionnement, la stabilitÃ© et les performances de lâ€™API, plusieurs types de tests ont Ã©tÃ© mis en place tout au long de lâ€™Ã©tape 2 

- => Les tests visibles dans le sous dossier tests

- => Rapport de couverture des tests dans le dossier /htmlcov

### lancement des tests : pytest -v tests/


#  Ã‰tape 3 â€“ Monitoring et dÃ©tection dâ€™anomalies
ğŸ¯ Objectif

Dans cette troisiÃ¨me Ã©tape, l'objectif est de surveiller automatiquement l'activitÃ© de lâ€™API dÃ©ployÃ©e 


ğŸ§  Analyse des logs

Un script Python analyse_logs.py a Ã©tÃ© dÃ©veloppÃ© pour :

ğŸ” Lire et parser les logs :

Chargement des lignes JSON du fichier logs/predictions.log

Conversion en DataFrame pour une analyse plus simple

### lancement : python analyse_logs.py

ğŸ“Š Calculer les statistiques clÃ©s :

Temps de rÃ©ponse moyen / max / min

Distribution des scores de risque

Taux de "risques Ã©levÃ©s"

Moyennes mobiles (latence, CPUâ€¦)

ğŸ“‰ DÃ©tection automatique :

DÃ©rive des donnÃ©es : dÃ©tection dâ€™un changement significatif dans la distribution des inputs


ğŸ“ˆ 3. Visualisation 


Un dashboard.py avec Streamlit  :

- Afficher les  temps de rÃ©ponse, CPU, mÃ©moire

- Suivre en temps rÃ©el la distribution des scores

- DÃ©tecter visuellement les anomalies

### lancement : streamlit run dashboard.py


#  Ã‰tape 4 â€“ Optimisation des performances du modÃ¨le en production
Objectif

ğŸ” Profiling de lâ€™API

Un profiling de la fonction predict_credit_score() exposÃ©e dans app_gradio.py a Ã©tÃ© rÃ©alisÃ© Ã  lâ€™aide du module cProfile. Le fichier profiling.py contient ce profilage.

Exemple de lancement depuis le terminal :

### python profiling.py

Les rÃ©sultats sont sauvegardÃ©s au format .prof et visualisÃ©s via Snakeviz :

### snakeviz profiling_output3.prof



