import streamlit as st
import pandas as pd
import json
import numpy as np

# === Fichiers ===
LOG_PATH = "logs/predictions_log.jsonl"
DRIFT_REPORT = "logs/drift_report.html"

# === Titre ===
st.set_page_config(page_title="Monitoring API", layout="centered")
st.title("üìä Dashboard de Monitoring de l'API de Scoring Cr√©dit")

# === Chargement des logs ===
records = []
with open(LOG_PATH, "r") as f:
    for line in f:
        log = json.loads(line)
        row = log.get("input", {})
        row["duration"] = log.get("duration", None)
        row["prediction"] = log.get("prediction", None)
        records.append(row)

df = pd.DataFrame(records)

# === Statistiques g√©n√©rales ===
st.header("üìà Statistiques G√©n√©rales")
st.write(f"Nombre total de requ√™tes : `{len(df)}`")

if "duration" in df.columns:
    durations = df["duration"].astype(float)
    st.metric("üê¢ Latence moyenne (s)", round(durations.mean(), 3))
    st.metric("‚è±Ô∏è Latence max (s)", round(durations.max(), 3))
    st.metric("üêå % requ√™tes lentes (>95e)", f"{round(100 * len(durations[durations > durations.quantile(0.95)]) / len(durations), 1)} %")
else:
    st.warning("‚ö†Ô∏è Colonne 'duration' absente des logs.")

if "prediction" in df.columns:
    erreurs = df["prediction"].astype(str).isin(["", "None", "nan"]).sum()
    st.metric("‚ö†Ô∏è Taux d‚Äôerreur", f"{round(100 * erreurs / len(df), 2)} %")
else:
    st.warning("‚ö†Ô∏è Colonne 'prediction' absente des logs.")

# === Rapport de d√©rive (Data Drift) ===
st.header("üîç Rapport de d√©rive (Data Drift)")

try:
    with open(DRIFT_REPORT, "r", encoding="utf-8") as f:
        html_content = f.read()
        # ‚úÖ Permet le scroll horizontal et vertical
        st.components.v1.html(
            f"""
            <div style="overflow-x: auto; overflow-y: auto; width: 2000px; height: 1800px;">
                {html_content}
            </div>
            """,
            height=1000,
            scrolling=True
        )
except FileNotFoundError:
    st.error("Rapport de d√©rive non trouv√©. Veuillez ex√©cuter `analyse_logs.py` d'abord.")


